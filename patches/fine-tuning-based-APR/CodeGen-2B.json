{
    "2": {
        "patched_method": "  private void readUntilEndOfEntry() throws IOException {\n    if (localFileHeader.isDirectory() || localFileHeader.getCompressedSize() == -1) { \n      return;\n    }\n\n    if (endOfEntryBuffer == null) {\n      endOfEntryBuffer = new byte[512];\n    }\n\n    while (read(endOfEntryBuffer) != -1);\n  }\n",
        "diff": "    if (localFileHeader.isDirectory() || localFileHeader.getCompressedSize() == -1) { \n"
    },
    "5": {
        "patched_method": "    public @Override String getName() {\n    if (testName == null || testName.isEmpty()) { \n    \t\treturn \"(?)\";\n    \t}\n        return testName;\n    }\n",
        "diff": "    if (testName == null || testName.isEmpty()) { \n"
    },
    "34": {
        "patched_method": "\tprivate <K, I extends Iterable<?>> void writeRows(Map<K, String> headerMapping, Map<K, I> rowData, List<String> outputList, boolean useRowProcessor) {\n\t\ttry {\n\t\t\tIterator[] iterators = new Iterator[rowData.size()];\n\t\t\tObject[] keys = new Object[rowData.size()];\n\t\t\tfinal Map<Object, Object> rowValues = new LinkedHashMap<Object, Object>(rowData.size());\n\n\t\tif (headers!= null){ \n\t\t\t\tif(headerMapping != null){\n\t\t\t\t\tsetHeadersFromMap(headerMapping, true);\n\t\t\t\t} else {\n\t\t\t\t\tsetHeadersFromMap(rowData, true);\n\t\t\t\t}\n\t\t\t\tif(isHeaderWritingEnabled && recordCount == 0){\n\t\t\t\t\toutputList.add(writeHeadersToString());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint length = 0;\n\t\t\tfor (Map.Entry<K, I> rowEntry : rowData.entrySet()) {\n\t\t\t\titerators[length] = rowEntry.getValue() == null ? null : rowEntry.getValue().iterator();\n\t\t\t\tkeys[length] = rowEntry.getKey();\n\t\t\t\trowValues.put(rowEntry.getKey(), null);\n\t\t\t\tlength++;\n\t\t\t}\n\t\t\tboolean nullsOnly;\n\n\t\t\tdo {\n\t\t\t\tnullsOnly = true;\n\t\t\t\tfor (int i = 0; i < length; i++) {\n\t\t\t\t\tIterator<?> iterator = iterators[i];\n\t\t\t\t\tboolean isNull = iterator == null || !iterator.hasNext();\n\t\t\t\t\tnullsOnly &= isNull;\n\t\t\t\t\tif (isNull) {\n\t\t\t\t\t\trowValues.put(keys[i], null);\n\t\t\t\t\t} else {\n\t\t\t\t\t\trowValues.put(keys[i], iterator.next());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!nullsOnly) {\n\t\t\t\t\tif (outputList == null) {\n\t\t\t\t\t\tif (useRowProcessor) {\n\t\t\t\t\t\t\tprocessRecord((Map) headerMapping, (Map) rowValues);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\twriteRow((Map) headerMapping, (Map) rowValues);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (useRowProcessor) {\n\t\t\t\t\t\t\toutputList.add(processRecordToString((Map) headerMapping, (Map) rowValues));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\toutputList.add(writeRowToString((Map) headerMapping, (Map) rowValues));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} while (!nullsOnly);\n\t\t} catch (Throwable t) {\n\t\t\tthrow throwExceptionAndClose(\"Error processing input rows from map\", t);\n\t\t}\n\t}\n",
        "diff": "\t\tif (headers!= null){ \n"
    },
    "37": {
        "patched_method": "\tvoid mapValuesToFields(T instance, Object[] row, Context context) {\n\t\tif (row.length > lastFieldIndexMapped) {\n\t\t\tthis.lastFieldIndexMapped = row.length;\n\t\t\tmapFieldIndexes(context, row, context.headers(), context.extractedFieldIndexes(), context.columnsReordered());\n\t\t}\n\n\t\tint last = row.length < readOrder.length ? row.length : readOrder.length;\n\t\tint i = 0;\n\t\tfor (; i < last; i++) {\n\t\t\tFieldMapping field = readOrder[i];\n\t\t\tif (field != null) {\n\t\t\t\tObject value = row[i];\n\t\t\t\tfield.write(instance, value);\n\t\t\t}\n\t\t}\n\n\t\tif (row.length == readOrder.length) { \n\t\t\ti = last;\n\t\t\tfor (; i < readOrder.length; i++) {\n\t\t\t\tFieldMapping field = readOrder[i];\n\t\t\t\tif (field != null) {\n\t\t\t\t\tObject value = conversions.applyConversions(i, null, null);\n\t\t\t\t\tfield.write(instance, value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (missing != null) {\n\t\t\tfor (i = 0; i < missing.length; i++) {\n\t\t\t\tObject value = valuesForMissing[i];\n\t\t\t\tif (value != null) {\n\t\t\t\t\tFieldMapping field = missing[i];\n\t\t\t\t\tfield.write(instance, value);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t}\n",
        "diff": "\t\tif (row.length == readOrder.length) { \n"
    },
    "84": {
        "patched_method": "  public static Expression concatChunksForceString(List<? extends Expression> chunks) {\n    if (!chunks.isEmpty()\n        && chunks.get(0).isRepresentableAsSingleExpression()\n        && JsExprUtils.isStringLiteral(\n            chunks.get(0).assertExprAndCollectRequires(RequiresCollector.NULL))) {\n      return concatChunks(chunks);\n    } else if (chunks.size() > 1\n        && chunks.get(1).isRepresentableAsSingleExpression()\n        && JsExprUtils.isStringLiteral(\n            chunks.get(1).assertExprAndCollectRequires(RequiresCollector.NULL))) {\n      return concatChunks(chunks);\n    } else {\n      return concatChunks(\n    ImmutableList.of(LITERAL_EMPTY_STRING, concatChunks(chunks))); \n    }\n  }\n",
        "diff": "    ImmutableList.of(LITERAL_EMPTY_STRING, concatChunks(chunks))); \n"
    },
    "96": {
        "patched_method": "    public void finish() throws IOException {\n        if (!closed) {\n            closed = true;\n            try {\n                if (this.runLength > 0) {\n                    writeRun();\n                }\n                this.currentChar = -1;\n                endBlock();\n                endCompression();\n            } finally {\n                this.out.close(); \n                this.blockSorter = null;\n                this.data = null;\n            }\n        }\n    }\n",
        "diff": "                this.out.close(); \n"
    }
}